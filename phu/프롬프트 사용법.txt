1. 명령어는 최대한 구체적으로, 영어로 작성

2. 역할을 부여하여 명령 (ex. 사회학과 교수라고 생각하고, 광고주라 생각하고) - > 생각보다 효율 떨어짐

3. 하이퍼 파라미터 활용 https://www.youtube.com/watch?v=kmI9G5IrSQI

https://mokeya.tistory.com/420

Temperature (온도): 온도는 모델의 출력 다양성을 조절하는 데 사용됩니다. 낮은 온도 값 (예: 0.2)은 보다 확실하고 일관된 응답을 생성하며, 높은 온도 값 (예: 0.8)은 더욱 다양하고 창의적인 응답을 생성합니다.

Max tokens (최대 토큰 수): 모델이 출력으로 생성할 최대 토큰 수를 제한할 수 있습니다. 이를 통해 응답의 길이를 제어하거나 긴 문장을 생성하지 않도록 할 수 있습니다.

Top p (Nucleus sampling): Top p는 출력 단어의 확률 분포에서 얼마나 많은 확률을 포함할지 결정합니다. 작은 Top p 값을 사용하면 모델이 더 정확하고 일관된 단어를 선택하게 되고, 큰 Top p 값을 사용하면 다양성이 높아질 수 있습니다.

Frequency penalty (빈도 패널티): 빈도 패널티는 모델이 이미 출력에 포함된 단어를 피하도록 유도하는 역할을 합니다. 높은 빈도 패널티 값을 사용하면 모델이 중복된 단어를 자주 사용하지 않도록 할 수 있습니다.

===================================================================================
1. Temperature
해당 기사의 헤드라인을 'GPT 하이퍼파라미터 온도를 0.3'로 설정하고 작성해줘

ChatGPT
현대카드 및 현대커머셜, 고금리 및 경기 회복 지연으로 어려움 겪는 금융 취약 계층 지원 방안 발표

해당 기사의 헤드라인을 'GPT 하이퍼파라미터 온도를 0.2'로 설정하고 작성해줘

ChatGPT
현대카드 및 현대커머셜, 금융 취약 계층을 위한 상생금융 지원 방안 발표
===================================================================================


4. 질문을 단계별로 나눠서 작성
운동을 처음 접한 사람이라고 생각하고 일주일 다이어트 식단을 짜줘
-> 시트로 작성해줘
-> 위의 내용에 이어서 닭가슴살을 제외하고 식단을 시트로 작성해줘

5. 구두점과 서식, 문장부호 활용

